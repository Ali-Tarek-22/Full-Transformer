# Full-Transformer
My full implementation of a transformer based on the architecture presented in the "Attention is all you need" paper
